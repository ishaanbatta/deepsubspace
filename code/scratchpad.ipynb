{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import nibabel as nib\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pdb\n",
    "import argparse\n",
    "import json \n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut \n",
    "from models import AN3Ddr_lowresMax\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdpath = '../out/results/latest/mt_AN3DdrlrMx_fkey_lT1_scorename_labels_3way_iter_10_nc_2_rep_0_bs_32_lr_0.0001_espat_20/model_state_dict.pt'\n",
    "\n",
    "model = AN3Ddr_lowresMax(num_classes=2, num_channels=1, num_groups=1)\n",
    "model.load_state_dict(torch.load(mdpath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = '/data/users2/ibatta/data/features/fmrimeasures/ADNI/nii/002_S_6007/Axial_rsfMRI__Eyes_Open_/2017-03-31_10_40_49.0/S551365/rest/'\n",
    "\n",
    "f1 = nib.load(d+'swarest1_tsavg.nii').get_fdata()\n",
    "f2 = nib.load(d+'swarest1_ALFF.nii').get_fdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.prod(f1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(f1-f2 > 10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = (f1 - f1.min()) / (f1.max()-f1.min())\n",
    "f2 = (f2 - f2.min()) / (f2.max()-f2.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(f1-f2 > 0.01).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = '/data/qneuromark/Data/ADNI/Updated/fMRI/ADNI/177_S_6335/Axial_MB_rsfMRI__Eyes_Open_/2020-07-22_12_56_01.0/S951207/rest/swarest1.nii'\n",
    "dl = nib.load(fl).get_fdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir='/data/qneuromark/Data/ADNI/Updated/fMRI/Results/GIGICA/041_S_6401/Axial_rsfMRI__Eyes_Open_/2018-06-12_13_51_03.0/S694594/rest/swarest1/'\n",
    "f1 = 'adni_aa__sub01_component_ica_s1_.nii'\n",
    "f2 = 'adni_aa__ica_c1-1.mat'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = nib.load(basedir + f1).get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = loadmat(basedir + f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2['ic'].shape, d2['tc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "53*63*52, 66529*194"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  QC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Valued Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ADNI'\n",
    "filemapper = json.load(open('../in/filemapper.json','r'))\n",
    "\n",
    "measures = list(filemapper['filename']['ADNI'].keys())\n",
    "\n",
    "nanfiles = []\n",
    "numnans = []\n",
    "badfiles = []\n",
    "\n",
    "for m in measures: \n",
    "    basepath_mapper = filemapper['basepathmapper'][dataset][m]\n",
    "    basedir = filemapper['basedir'][dataset][basepath_mapper]\n",
    "    # basedir = '/data/qneuromark/Data/ADNI/Updated/fMRI/ADNI/'\n",
    "    filename = filemapper['filename']['ADNI'][m]\n",
    "    # filename = 'swarest1.nii'\n",
    "    for dir in open('../in/%s_MMR180.csv'%basepath_mapper,'r+').read().split('\\n')[:-1]:\n",
    "        fullpath = basedir + dir + filename\n",
    "        scandata = nib.load(fullpath).get_fdata()\n",
    "        if np.isnan(scandata).sum() > 0:\n",
    "            nn = np.isnan(scandata).sum()\n",
    "            print(nn)\n",
    "            print(fullpath)\n",
    "            nanfiles.append(fullpath)\n",
    "            numnans.append(nn)\n",
    "        if np.abs(np.std(scandata)) < 0.001:\n",
    "            print(np.abs(np.std(scandata)))\n",
    "            print(fullpath)\n",
    "            badfiles.append(fullpath)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../in/badfiles_measures.txt','w+') as f:\n",
    "    f.write('\\n'.join(badfiles))\n",
    "\n",
    "with open('../in/numnans_measures.txt','w+') as f:\n",
    "    f.write('\\n'.join(['%s,%d'%(nanfiles[i],numnans[i]) for i in range(len(nanfiles))]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(['ALFF', 'DCw', 'DCb', 'fALFF', 'KccReHo', 'VMHC', 'lT1', 'ALFF,DCw,DCb,fALFF,KccReHo,VMHC,lT1', 'ALFF,lT1', 'DCw,lT1', 'DCb,lT1', 'fALFF,lT1', 'KccReHo,lT1', 'VMHC,lT1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../in/vars.txt', 'r+') as f:\n",
    "    scores = f.read().split('\\n')[:-1]\n",
    "scores_file = '../in/analysis_SCORE_MMR180d.csv'\n",
    "df = pd.read_csv(scores_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['age'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for score in scores:\n",
    "    print('%s, %s'%(score,df[score].dtype))\n",
    "    dt = df[score].dtype\n",
    "    if not 'float' in str(dt):\n",
    "        df[score] = df[score].fillna(df[score].mode())\n",
    "    else:\n",
    "        df[score] = df[score].fillna(df[score].median())\n",
    "\n",
    "df.to_csv('../in/analysis_SCORE_MMR180d_imputed.csv',  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '../out/performances/baseline/allcombos_baseline_reg.png '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_file = '.'.join(output_file.split('.')[:-1]) + '_pvals.' + output_file.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = ['tsavg','tsmedian','tsmax','tsmin']\n",
    "    # fns.remove('hT1')\n",
    "    # fns.remove('PerAF')\n",
    "    # fns.append(','.join(fns)) #multimodal with all features into DL model\n",
    "    fns += [fi+',lT1' for fi in fns if 'lT1' not in fi] # multimodal with 2 modalities: with one fmri measure with low-res smri \n",
    "    # fns.append(','.join([','.join(fns) for i in range(8)] )) # Testing 56 groups for future  \n",
    "    print(fns)\n",
    "\n",
    "    # # Map iter value (slurm taskID) to training sample size (tss) and crossvalidation repetition (rep)\n",
    "    fv, rv = np.meshgrid(np.arange(len(fns)), np.arange(cfg.nReps))\n",
    "    fv = fv.reshape((1, np.prod(fv.shape)))\n",
    "    rv = rv.reshape((1, np.prod(rv.shape)))\n",
    "    fkey = fns[fv[0][cfg.iter]]\n",
    "    rep = rv[0][cfg.iter]\n",
    "    print(fkey, rep)\n",
    "    cfg.fkey = fkey\n",
    "    cfg.nch = len(fkey.split(','))\n",
    "    cfg.rep = rep\n",
    "    print(cfg.iter, cfg.tss, cfg.rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = json.load(open('../in/filemapper.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = list(fm['filename']['ADNI'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = ['tsavg','tsmedian','tsmax','tsmin']\n",
    "# fns.remove('hT1')\n",
    "# fns.remove('PerAF')\n",
    "# fns.append(','.join(fns)) #multimodal with all features into DL model\n",
    "fns += [fi+',lT1' for fi in fns if 'lT1' not in fi] # multimodal with 2 modalities: with one fmri measure with low-res smri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "fv, rv, sv = np.meshgrid(np.arange(len(fns)), np.arange(10), np.arange(8))\n",
    "fv = fv.reshape((1, np.prod(fv.shape)))\n",
    "rv = rv.reshape((1, np.prod(rv.shape)))\n",
    "sv = sv.reshape((1, np.prod(sv.shape)))\n",
    "\n",
    "for i in range(80):\n",
    "    fkey = fns[fv[0][i]]\n",
    "    rep = rv[0][i]\n",
    "    scr = sv[0][i]\n",
    "    print(fkey, rep, scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv.shape, rv.shape, sv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "fns.remove('hT1')\n",
    "fns.remove('PerAF')\n",
    "\n",
    "fv, rv = np.meshgrid(np.arange(len(fns)), np.arange(10))\n",
    "fv = fv.reshape((1, np.prod(fv.shape)))\n",
    "rv = rv.reshape((1, np.prod(rv.shape)))\n",
    "\n",
    "for i in range(80):\n",
    "    fkey = fns[fv[0][i]]\n",
    "    rep = rv[0][i]\n",
    "    \n",
    "    print(i,fkey, rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_config(config_string):\n",
    "    \"\"\"\n",
    "    Computes the set of test accuracy for the string corresponding to the config_string. \n",
    "    The config strings should represent one of the directory. \n",
    "    \"\"\"\n",
    "\n",
    "    basedir = '../out/results/latest/'\n",
    "    cmd = 'cat %s%s/test.csv | grep -v acc_te | cut -f2 -d\\\",\\\"'%(basedir,config_string)\n",
    "    output_stream = os.popen(cmd)\n",
    "    test_accs = np.array(output_stream.read().split('\\n')[:-1], dtype=float)\n",
    "    return test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_string = 'AN3Ddr_lowresMax_fkey_ALFF_scorename_labels_3way_iter_*_nc_2_rep_*_bs_32_lr_1e-05_espat_20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = summarize_config(config_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = summarize_config('AN3Ddr_lowresMax_fkey_ALFF_scorename_labels_3way_iter_*_nc_2_rep_*_bs_32_lr_1e-05_espat_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 30\n",
    "k_te = 4\n",
    "k_va = 5\n",
    "nreps = 3\n",
    "\n",
    "all_labels = np.array(list(range(0,30)), dtype=int) // 10\n",
    "\n",
    "# selelct specific labels if needed for binary classification\n",
    "select_labels = [0,2]\n",
    "labels = np.array([li for li in all_labels if li in select_labels], dtype=int)\n",
    "sli = np.array([i for i in range(len(all_labels)) if all_labels[i] in select_labels], dtype=int)\n",
    "\n",
    "\n",
    "for ri in np.arange(nreps):\n",
    "\ttri, test_indices = train_test_split(np.arange(len(labels)), test_size=1.0/k_te, shuffle=True, stratify=labels, random_state=108+ri)\n",
    "\ttr_idx, val_idx = train_test_split(np.arange(len(tri)), test_size=1/k_va, shuffle=True, stratify=labels[tri], random_state=108+ri)\n",
    "\ttrain_indices, val_indices = tri[tr_idx], tri[val_idx]\n",
    "\n",
    "\tprint(all_labels[sli[train_indices]], all_labels[sli[val_indices]], all_labels[sli[test_indices]])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.loadtxt('../out/temp1.txt').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.loadtxt('../out/temp2.txt').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\tnp.savetxt(outdir+'/tr_r'+str(ri)+'.csv', train_indices, fmt='%d')\n",
    "\tnp.savetxt(outdir+'/va_r'+str(ri)+'.csv', val_indices, fmt='%d')\n",
    "\tnp.savetxt(outdir+'/te_r'+str(ri)+'.csv', test_indices, fmt='%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr, va = train_test_split(np.arange(n), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# Try Merge\n",
    "fl = '../in/lowresfilelist_ADNI_SMRI.txt'\n",
    "sm = '../in/analysis_SCORE_SMRI_fpL.csv'\n",
    "\n",
    "df_fl = pd.read_csv(fl)\n",
    "df_sm = pd.read_csv(sm).iloc[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(12):\n",
    "    tv, rv = np.meshgrid([], np.arange(3))\n",
    "    tv = tv.reshape((1, np.prod(tv.shape)))\n",
    "    rv = rv.reshape((1, np.prod(tv.shape)))\n",
    "    tss = tv[0][iter]\n",
    "    rep = rv[0][iter]\n",
    "    print(tss, rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.loadtxt('../in/SampleSplits/ADNI/3way/te_r0.csv', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sm = df_sm.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('AA_DL2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f89dc90b8ce3db6e3c871b8c318edc37b911bdfa52c259173116bc55490ddb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
